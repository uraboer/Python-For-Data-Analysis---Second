{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### NumPy\n",
    "NumPy,short of Numerical Python, has long been a cornerstone of numerical computing in Python. It provides the data structures, algorithms, and library glue needed for most sicentific applications involving numerical data in Python. NumPy contains, among outher things:\n",
    "\n",
    "- A fast and efficient multidimensional array object ndarrary\n",
    "- Functions for performing element-wise computations with arrays or mathematical operations between arrays\n",
    "- Tools for reading and writeing array-based datasets to disk\n",
    "- Linear algebra operations, Fourier transform, and random number generation\n",
    "- A mature C API to enable Python extensions and native C or C++ code to access NumPy's data structures and computational facilities\n",
    "\n",
    "Beyond the fast array-processing capabilities that NumPy adds to Python, one of its primary uses in data analysis is as container for data to passed between algorithms and libraries. For numerical data, NumPy arrays are more efficient for storing and manipulating data than the other built-in Python data structures. Also,libraries written in a lower-level language, such as C or Fortran, can operate on the data stored in a NumPy array without copying data into some other memory representation. Thus, many numerical computing tools for Python either assume NumPy arrays as a primary data structure or else target seamless interoperatbility with NumPy.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### pandas\n",
    "pandas provides high-level data structures and functions designed to make working with structured or tabular data fast, easy, and expressive. Since its emergence in 2010, it has helped enable Python to be a  powerful and productive data analysis environment. The primary objects in pandas that will be used in this book are the DataFrame, a tabular, column-oriented data structure with both row and column labels, and the Series, a one-dimensional labeled array object.\n",
    "\n",
    "pandas blends the high-performance, array-computing ideas of NumPy with the flexible data manipulation capabilities of spreadsheets and relational databases (such as SQL). It provides sophisticated indexing functionality to make it easy to reshape, slice and dice, perform aggregations, and select subsets of data. Since data manipulation, preparation, and cleaning is such an important skill in data analysis, pandas is one of the primary focuses of this book.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### matplotlib\n",
    "matplotlib is the most popular Python library for producing plots and other two-dimensional data visualization. It was originally created by John D. Hunter and it now maintained by a large team of developers. It is designed for creating plots suitable for publication. While there are other visualization libraries available to Python programmers, matplotlib is the most widely used and as such has generally good integration with the rest of the ecosystem. I think it is a safe choice as a default visualization tool."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### IPython and Jupyter\n",
    "The IPython project began in 2001 as Fernando Perezs side project to make a better interactive Python interpreter. In the subsequent 16 years it has become one of the most important tools in the modern Python data stack. While it does not provide any computational or data analytical tools by itself, IPython is designed from the ground up to maximize your productivity in both interactive computing and software development. It encourages an execute-explore workflow instead of the typical edit-compile-run workflow of many other programming languages. It also provides easy acdess to your operating system's shell and filesystem. Since much of data analysis coding involves exploration, trial and error, and iteration, IPython can help you get the job done better. \n",
    "\n",
    "In 2014, Fernando and the IPython team announced the Jupyter project, a broader initiative to design language-agnostic interactive compting tools. The IPython web notebook became the Jupyter notebook, with support now for over 40 programming languages. The IPython system can now be used as a kernel for useing Python with Jupyter.\n",
    "\n",
    "IPython itself has become a component of the much broader Jupyter open source project, which provides a productivve environment for interactive and exploratory computing. Its oldest and simplest \"mode\" is as an enhanced Python shell designed to\n",
    "accelerate the writing, testing, and debugging of Python code. You can also use the IPython system through the Jupyter Notebook, an interactive web-based code \"notebook\" offering support for dozens of programming languages. The IPython shell and Jupyter notebooks are especially useful for data exploration and visualization.\n",
    "\n",
    "The Jupyter notebook system also allows you to author content in Markdown and HTML, providing you a means to create to create rich documents with code and text. Other programming languages have also implemented kernels for Jupyter to enable you to use languages other than Python in Jupyter."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SciPy\n",
    "SciPy is a collection of packages addressing a number of different standard problem domains in scientific computing. Here is a sampling of the packages included:\n",
    "\n",
    "- sicpy.integrate:积分,微分\n",
    "\n",
    "Numerical integration routines and differential equation solvers\n",
    "\n",
    "- scipy.linalg:线性代数\n",
    "\n",
    "Linear algebra routines and matrix decompositions extending beyond those provided in numpy.linalg\n",
    "\n",
    "- scipy.optimize:优化\n",
    "\n",
    "Function optimizers (minimizers) and root finding algorithms\n",
    "\n",
    "- scipy.signal:信号\n",
    "\n",
    "Signal processing tools\n",
    "\n",
    "- scipy.special:稀疏矩阵\n",
    "\n",
    "Sparse matrices and sparse linear system solvers\n",
    "\n",
    "- scipy.special:公式翻译式\n",
    "\n",
    "Wrapper around SPECFUN, a Fortran library implementing many common mathematical functions, such as the gamma function\n",
    "\n",
    "- scipy.stats:统计\n",
    "\n",
    "Standard continuous and discrete probability distributions (density functions, samplers, continuyous distribution functions), various statistical tests, and more descriptive statistics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### scikit-learn\n",
    "Since the project'inception in 2010, scikit-learn has become the premier general-purpose machine learning toolkit for Python programmers. It includes submodules for such models as:\n",
    "\n",
    "- Classification: SVM, nearest neighbors, random forest, logistic regression, etc.\n",
    "\n",
    "- Regression: Lasso, ridge regression, etc.岭回归\n",
    "\n",
    "- Clustering: k-means, spectral clustering, etc.谱聚类\n",
    "\n",
    "- Dimensionality reduction: PCA, feature selection, matrix factorization, etc.矩阵因子分解\n",
    "\n",
    "- Model selection: Grid search, cross-validation, metrics 网格搜索,交叉验证,权值\n",
    "\n",
    "- Preprocessing: Feature extraction, normalization 特征抽取,正则化\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### statsmodels\n",
    "statsmodels is a statistical analysis package that was seeded by work from Stanford University statistics professor Jonathan Taylor, who implemented a number of regression analysis models popular in R programming language. Skipper Seabold and Josef Perktold formally created the new statsmodels project in 2010 and since then have grown the project to a critical mass of engaged users and contibutors. Nathaniel Smith developed the Patsy project, which provides a formula or model specification framework for statsmodels inspired by R's formula system.\n",
    "\n",
    "Compared wiht scikit-learn, statsmodels contains algorithms for classical (primarily frequentist) statistics and econometrics. This includes such submodules as:\n",
    "\n",
    "- Regression models: Linear regression, generalized linear models广义线性模型, robust linear models, linear mixed effects models, etc.\n",
    "\n",
    "- Analysis of variance (ANOVA)方差分析\n",
    "\n",
    "- Times series analysis: AR, ARMA, ARIMA, VAR, and other models\n",
    "\n",
    "- Nonparametric methods:Kernel density estimation, kernel regression\n",
    "\n",
    "- Visualization of statistical model results\n",
    "\n",
    "statsmodels is more focused on statistical inference, providing uncertainty estimates and p-values for parameters.scikit-learn, by contrast, is more prediction-focused."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
